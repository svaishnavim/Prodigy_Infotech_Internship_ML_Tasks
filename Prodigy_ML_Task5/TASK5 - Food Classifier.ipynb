{"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11959,"sourceType":"datasetVersion","datasetId":8544}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorboard --quiet\n%reload_ext tensorboard","metadata":{"id":"n3osYtAGrALV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tensorflow Modules\nimport tensorflow as tf\nfrom tensorboard.plugins.hparams import api as hp\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Fundamental Modules\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nfrom itertools import product\nimport pandas as pd\nimport numpy as np\nimport random\nimport datetime\nimport zipfile\nimport pathlib\nimport os","metadata":{"id":"OHlX3hj1xdit"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def view_random_images(\n    target_dir,\n    target_class\n    ):\n  target_folder = os.path.join(target_dir, target_class)\n  random_image = random.sample(os.listdir(target_folder), 1)\n  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n\n  plt.imshow(img)\n  plt.title(target_class + \" with a shape of: \" + str(img.shape))\n  plt.axis(\"off\")\n\n  return img\n\ndef resize_images(\n    file_path: str,\n    img_shape: int = 224\n    ):\n  image = tf.io.read_file(file_path)\n  image = tf.image.decode_image(image)\n  image = tf.image.resize(image,\n                          size=[img_shape, img_shape]\n                          )\n  image = tf.expand_dims(image / 255., axis=0)\n\n  return image\n\ndef plot_predictions(\n    target_dir: str,\n    model\n    ):\n  class_labels = [\"pizza\", \"steak\"]\n  target_class = random.choice(class_labels)\n  target_folder = os.path.join(target_dir, target_class)\n\n  random_image = random.choice(os.listdir(target_folder))\n  image_path = os.path.join(target_folder,\n                            random_image)\n  resized_image = resize_images(image_path)\n\n  prediction = model.predict(resized_image)\n  prediction_object = class_labels[int(tf.round(prediction))]\n\n  image = mpimg.imread(image_path)\n  plt.imshow(image)\n  plt.title(f\"Predicted Object: {prediction_object}\")\n  plt.axis(False)\n  plt.show()","metadata":{"id":"Cr7K668-OmFh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n\nzip_ref = zipfile.ZipFile(\"pizza_steak.zip\")\nzip_ref.extractall()\nzip_ref.close()","metadata":{"id":"YOhYpb0Cv2Ln","outputId":"0f0c4631-3711-49ef-9ef2-27792cc58f0e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = pathlib.Path(\"pizza_steak/train\")\nclass_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")]))\nprint(class_names)","metadata":{"id":"9s3Vwc3KL0XB","outputId":"c8455f59-98a4-4a88-b22f-938568fe36c1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_type = [\"steak\", \"pizza\"]\nnum_rows = len(class_type)\nnum_cols = 5\n\nfig, axes = plt.subplots(num_rows, num_cols, figsize=(16, 7))\n\nfor i, food in enumerate(class_type):\n    for j in range(num_cols):\n        ax = axes[i, j]\n        img = view_random_images(target_dir=\"pizza_steak/train/\",\n                                 target_class=food)\n        ax.imshow(img)\n        ax.set_title(food + str(img.shape))\n        ax.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"fV90wrVbWdcf","outputId":"52344f2b-8ecb-492f-b136-c81c4c495bc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(1212124)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True\n    )\n\n\ntrain_data = train_datagen.flow_from_directory(\n    directory=\"/content/pizza_steak/train\",\n    batch_size=32,\n    target_size=(224,224),\n    class_mode=\"binary\",\n    shuffle=False,\n    seed=1212124\n  )\n\n\nshuffled_training_data = train_datagen.flow_from_directory(\n    directory=\"/content/pizza_steak/train\",\n    batch_size=32,\n    target_size=(224,224),\n    class_mode=\"binary\",\n    shuffle=True,\n    seed=1212124\n  )\n\nnon_augmented_train_datagen = ImageDataGenerator(\n    rescale=1./255\n)\n\nnon_augmented_train_data = non_augmented_train_datagen.flow_from_directory(\n    directory=\"/content/pizza_steak/train\",\n    batch_size=32,\n    target_size=(224,224),\n    class_mode=\"binary\",\n    shuffle=False,\n    seed=1212124\n  )\n\n\ntest_datagen = ImageDataGenerator(\n    rescale=1./255\n    )\n\ntest_data = test_datagen.flow_from_directory(\n    directory=\"/content/pizza_steak/test\",\n    batch_size=32,\n    target_size=(224,224),\n    class_mode=\"binary\",\n    seed=1212124\n  )","metadata":{"id":"W6LD3KOqXFkh","outputId":"b8e6892a-390a-4ba0-8c1c-c9334cb339d8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"non_augmented_images, non_augmented_labels = non_augmented_train_data.next()\naugmented_images, augmented_labels = train_data.next()","metadata":{"id":"UW1cPRv0GEpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Non-augmented Image Shape {non_augmented_images.shape}, \\nAugmented Image Shape: {augmented_images.shape}\")","metadata":{"id":"Ptjj6wkGPM6x","outputId":"3edcf3c7-0104-4349-ae87-554071e9fed9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_number = random.randint(0, 32)\nplt.imshow(non_augmented_images[random_number])\nplt.title(f\"Original Image\")\nplt.axis(False)\nplt.figure()\nplt.imshow(augmented_images[random_number])\nplt.title(f\"Augmented Image\")\nplt.axis(False);","metadata":{"id":"2keNpvfAMP7J","outputId":"a6486ded-8c4e-46a3-da46-d7de2fc999d7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(42)\n\n# Visualize the training on Tensorboard\nlog_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n# Save model checkpoint with best epoch\ncb_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath=\"model_checkpoint/model-{epoch:02d}-{accuracy:.3f}.hdf5\",\n    monitor=\"val_accuracy\",\n    mode=\"max\",\n    save_best_only=True,\n    save_weights_only=True,\n    verbose=0\n)\n\n# Drop the learning rate when model does not improve its performance metric\ncb_reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_accuracy\",\n    mode=\"max\",\n    factor=0.1,\n    patience=5,\n    verbose=0,\n    min_lr=1e-7\n)\n\n# Force stop the training if model does not improve for a specific number of epochs\ncb_earlystop = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_accuracy\",\n    mode=\"max\",\n    min_delta=0.001,\n    patience=10,\n    verbose=0,\n)\n","metadata":{"id":"BsDOOgxYwXB_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FV_101(tf.keras.Model):\n  def __init__(\n        self,\n        filters: int,\n        kernel_size: int,\n        strides: int,\n        activations: str,\n        num_inputs: tuple[int],\n        pool_size: tuple[int],\n        units: int\n        ):\n\n    super(FV_101, self).__init__(name=\"\")\n    self.filters=filters\n    self.kernel_size=kernel_size\n    self.strides=strides\n    self.activations = activations\n    self.num_inputs=num_inputs\n    self.pool_size=pool_size\n    self.units=units\n\n    self.conv2d_1 = tf.keras.layers.Conv2D(\n        filters=self.filters,\n        kernel_size=self.kernel_size,\n        strides=self.strides,\n        activation=self.activations,\n        kernel_initializer=tf.keras.initializers.LecunNormal(seed=1212124),\n        bias_initializer=tf.keras.initializers.LecunNormal(seed=1212124),\n        input_shape=self.num_inputs,\n        name=\"conv2d_1\"\n    )\n\n    self.maxpool_1 = tf.keras.layers.MaxPool2D(\n        pool_size=self.pool_size,\n        strides=self.strides,\n        padding=\"valid\",\n        name=\"maxpool_1\"\n    )\n\n\n    self.conv2d_2 = tf.keras.layers.Conv2D(\n        filters=self.filters,\n        kernel_size=self.kernel_size,\n        strides=self.strides,\n        activation=self.activations,\n        kernel_initializer=tf.keras.initializers.LecunNormal(seed=1212124),\n        bias_initializer=tf.keras.initializers.LecunNormal(seed=1212124),\n        name=\"conv2d_2\"\n    )\n\n    self.maxpool_2 = tf.keras.layers.MaxPool2D(\n        pool_size=self.pool_size,\n        strides=self.strides,\n        padding=\"valid\",\n        name=\"maxpool_2\"\n    )\n\n    self.conv2d_3 = tf.keras.layers.Conv2D(\n        filters=self.filters,\n        kernel_size=self.kernel_size,\n        strides=self.strides,\n        activation=self.activations,\n        kernel_initializer=tf.keras.initializers.LecunNormal(seed=1212124),\n        bias_initializer=tf.keras.initializers.LecunNormal(seed=1212124),\n        name=\"conv2d_3\"\n    )\n\n    self.maxpool_3 = tf.keras.layers.MaxPool2D(\n        pool_size=self.pool_size,\n        strides=self.strides,\n        padding=\"valid\",\n        name=\"maxpool_3\"\n    )\n\n    self.conv2d_4 = tf.keras.layers.Conv2D(\n        filters=self.filters,\n        kernel_size=self.kernel_size,\n        strides=self.strides,\n        activation=self.activations,\n        kernel_initializer=tf.keras.initializers.LecunNormal(seed=1212124),\n        bias_initializer=tf.keras.initializers.LecunNormal(seed=1212124),\n        name=\"conv2d_4\"\n    )\n\n    self.maxpool_4 = tf.keras.layers.MaxPool2D(\n        pool_size=self.pool_size,\n        strides=self.strides,\n        padding=\"valid\",\n        name=\"maxpool_4\"\n    )\n\n    self.flat = tf.keras.layers.Flatten(name=\"flat_1\")\n    self.dns = tf.keras.layers.Dense(\n        units=self.units,\n        activation=self.activations,\n        kernel_initializer=tf.keras.initializers.LecunNormal(seed=1212124),\n        bias_initializer=tf.keras.initializers.LecunNormal(seed=1212124),\n        name=\"dense_1\"\n        )\n    self.outpt = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")\n\n\n  def call(self, inputs):\n      x = self.conv2d_1(inputs)\n      x = self.maxpool_1(x)\n      x = self.conv2d_2(x)\n      x = self.maxpool_2(x)\n      x = self.conv2d_3(x)\n      x = self.maxpool_3(x)\n      x = self.conv2d_4(x)\n      x = self.maxpool_4(x)\n      x = self.flat(x)\n      x = self.dns(x)\n      x = self.outpt(x)\n\n      return x","metadata":{"id":"uQAoiZJtper8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model = FV_101(\n    filters=10,\n    kernel_size=3,\n    strides=2,\n    activations=\"relu\",\n    num_inputs=(224, 224, 3),\n    pool_size=2,\n    units=100\n)\n\ncnn_model.compile(\n    loss=\"binary_crossentropy\",\n    optimizer=tf.keras.optimizers.Adam(),\n    metrics=[\"accuracy\"])\n\ncnn_model.fit(\n    shuffled_training_data,\n    epochs=100,\n    steps_per_epoch=len(train_data),\n    batch_size=32,\n    callbacks=[\n        cb_checkpoint,\n        cb_reducelr,\n        cb_earlystop,\n        tensorboard_callback\n        ],\n    verbose=1,\n    validation_data=test_data,\n    validation_steps=len(test_data)\n    )","metadata":{"id":"56n2yc6mvPCa","outputId":"c03e9786-f134-42c6-d4c2-610cfc5d5ed1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model.summary(\n    expand_nested=True,\n    show_trainable=True\n    )","metadata":{"id":"R1s6VByk3VMq","outputId":"c9015c3c-c8bf-46cc-b14d-da90386ea246"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Access to tensorboard\n!tensorboard dev upload --logdir ./logs/ \\\n  --name \"Food101 Image Classification Model Training\"","metadata":{"id":"2Tg5Udz683qu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_type = [\"steak\", \"pizza\"]\nnum_rows = len(class_type)\nnum_cols = 2\n\nfig, axes = plt.subplots(num_rows, num_cols, figsize=(16, 7))\n\nfor i, food in enumerate(class_type):\n    for j in range(num_cols):\n        ax = axes[i, j]\n        img = view_random_images(target_dir=\"/content/oos_image/\",\n                                 target_class=food)\n        ax.imshow(img)\n        ax.set_title(food + str(img.shape))\n        ax.axis(False)\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"SQHB1H5Yy8RG","outputId":"3c6bc088-9046-4c9f-9884-e7e78d5bdf04"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = [\"pizza\", \"steak\"]\nbase_dir = \"/content/oos_image/\"\n\nimage_list = []\n\nfor class_name in class_names:\n    class_dir = os.path.join(base_dir, class_name)\n    if os.path.exists(class_dir):\n        image_files = os.listdir(class_dir)\n        for image_file in image_files:\n            image_path = os.path.join(class_dir, image_file)\n            processed_image = resize_images(image_path)\n            image_list.append(processed_image)\n    else:\n        print(f\"Directory '{class_name}' not found.\")","metadata":{"id":"x0fIPvAB6q3N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_cnn_model = FV_101(\n    filters=10,\n    kernel_size=3,\n    strides=2,\n    activations=\"relu\",\n    num_inputs=(224, 224, 3),\n    pool_size=2,\n    units=100\n)\nbest_cnn_model(tf.zeros((1,224, 224, 3)))\nbest_cnn_model.load_weights(\"/content/model-30-0.843.hdf5\")","metadata":{"id":"-1vF1ic0EAzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prediction = best_cnn_model.predict(image_list)\nprint(class_names[int(tf.round(test_prediction))])","metadata":{"id":"iNdXkPof_LAX","outputId":"c289d330-4cc3-4945-db60-0ed661db87a2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_predictions(\n    target_dir = \"/content/pizza_steak/test/\",\n    model=best_cnn_model)","metadata":{"id":"8GJ8tWKVWlGY","outputId":"f0a8feab-a36a-408f-db8b-8149f02e9172"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_predictions(\n    target_dir = \"/content/oos_image/\",\n    model=best_cnn_model)","metadata":{"id":"JTGoKaIZBM2w","outputId":"bf92e756-bf68-4874-9668-cae06202d890"},"execution_count":null,"outputs":[]}]}